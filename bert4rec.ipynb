{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training a BERT4Rec baseline  "
      ],
      "metadata": {
        "id": "OFOTyC1NfxUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S0aDQ0_1ftDi",
        "outputId": "7049661d-2845-49de-800f-b0f714629c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers4rec[nvtabular,pytorch]\n",
            "  Downloading transformers4rec-0.1.16.tar.gz (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (4.64.1)\n",
            "Collecting transformers<4.19\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting betterproto<2.0.0\n",
            "  Downloading betterproto-1.2.5.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (1.12.0)\n",
            "Requirement already satisfied: pyarrow>=1.0 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (1.22.4)\n",
            "Collecting torchmetrics>=0.10.0\n",
            "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 KB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (1.13.1+cu116)\n",
            "Collecting nvtabular\n",
            "  Downloading nvtabular-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stringcase\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting grpclib\n",
            "  Downloading grpclib-0.4.3.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0->transformers4rec[nvtabular,pytorch]) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics>=0.10.0->transformers4rec[nvtabular,pytorch]) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (2.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nvtabular->transformers4rec[nvtabular,pytorch]) (1.10.1)\n",
            "Collecting merlin-dataloader>=0.0.2\n",
            "  Downloading merlin-dataloader-0.0.4.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting merlin-core>=0.2.0\n",
            "  Downloading merlin-core-0.10.0.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->transformers4rec[nvtabular,pytorch]) (1.58.0)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->transformers4rec[nvtabular,pytorch]) (1.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->transformers4rec[nvtabular,pytorch]) (3.19.6)\n",
            "Collecting dask>=2022.3.0\n",
            "  Downloading dask-2023.3.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (0.56.4)\n",
            "Collecting fsspec==2022.5.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.3.5)\n",
            "Collecting distributed>=2022.3.0\n",
            "  Downloading distributed-2023.3.0-py3-none-any.whl (945 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m945.4/945.4 KB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->transformers4rec[nvtabular,pytorch]) (6.0.4)\n",
            "Collecting h2<5,>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (4.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<4.19->transformers4rec[nvtabular,pytorch]) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<4.19->transformers4rec[nvtabular,pytorch]) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<4.19->transformers4rec[nvtabular,pytorch]) (1.2.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.3.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (0.12.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.0.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.7.0)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.0.0)\n",
            "Requirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (3.1.2)\n",
            "Collecting psutil>=5.7.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (6.2)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.1.2)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=2.1.0->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (3.15.0)\n",
            "Building wheels for collected packages: betterproto, transformers4rec, merlin-core, merlin-dataloader, grpclib, sacremoses, stringcase\n",
            "  Building wheel for betterproto (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for betterproto: filename=betterproto-1.2.5-py3-none-any.whl size=22012 sha256=6bd0c7c1d2959bd636c0400712b2c04176ba514e3d04c2fcb6f5bfe561c5a830\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/d8/2c/88deaa4bcf85c355055d31aebbc3b8e554ab38fd0823aa6f08\n",
            "  Building wheel for transformers4rec (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers4rec: filename=transformers4rec-0.1.16-py3-none-any.whl size=481577 sha256=a5421ad8a852246ee82eaf18404aee6dc494e7f8f80d0ac6fd557461f2e0e5f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/c0/d7/3d7d885412e6a92068a3f4149f6e84d0e5c49fd558118ae1bc\n",
            "  Building wheel for merlin-core (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for merlin-core: filename=merlin_core-0.10.0-py3-none-any.whl size=118957 sha256=9dbf0e22e77a37a22756dce155562e8039f8f92680b3301c4580ec1e73b3a2a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/61/f5/248b8e08a868d53576e56cab6d8dcad527c28a69499cf8486a\n",
            "  Building wheel for merlin-dataloader (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for merlin-dataloader: filename=merlin_dataloader-0.0.4-py3-none-any.whl size=40636 sha256=56810b5d0473a7a5cc01e53f1f068931d9a6ea9f9e22ca088eb988d41f346039\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/e2/06/e3d8eefc51ce919c86894c57ed23356ff99c8194635fe60f56\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.3-py3-none-any.whl size=77081 sha256=51ac953dff0e5c527c0433ce1961325b4d5bd1d82ed4cdbdfca05239ac88edcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/bf/37/810d98c051f7709adc84c97077afaef55a58725f879fc7f780\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ffc385f99d277482e0bfe327d56c78bca9ecfc2a118858aba29ac98bbc9aa834\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3587 sha256=6294450375b4b27a0c3137777fbd1364e43d362e2a330eb6afb5167b61ad8519\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/0e/31/bf265c64f2a4d24516e9923f1f6293c3bcbcde75e0d80ab47a\n",
            "Successfully built betterproto transformers4rec merlin-core merlin-dataloader grpclib sacremoses stringcase\n",
            "Installing collected packages: tokenizers, stringcase, sacremoses, psutil, hyperframe, hpack, fsspec, torchmetrics, huggingface-hub, h2, dask, transformers, grpclib, distributed, betterproto, transformers4rec, merlin-core, merlin-dataloader, nvtabular\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.1.0\n",
            "    Uninstalling fsspec-2023.1.0:\n",
            "      Successfully uninstalled fsspec-2023.1.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.2.1\n",
            "    Uninstalling dask-2022.2.1:\n",
            "      Successfully uninstalled dask-2022.2.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.2.1\n",
            "    Uninstalling distributed-2022.2.1:\n",
            "      Successfully uninstalled distributed-2022.2.1\n",
            "Successfully installed betterproto-1.2.5 dask-2023.3.0 distributed-2023.3.0 fsspec-2022.5.0 grpclib-0.4.3 h2-4.1.0 hpack-4.0.0 huggingface-hub-0.12.1 hyperframe-6.0.1 merlin-core-0.10.0 merlin-dataloader-0.0.4 nvtabular-1.8.1 psutil-5.9.4 sacremoses-0.0.53 stringcase-1.2.0 tokenizers-0.12.1 torchmetrics-0.11.3 transformers-4.18.0 transformers4rec-0.1.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers4rec[pytorch,nvtabular]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import torch \n",
        "import transformers4rec.torch as tr\n",
        "\n",
        "from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt\n",
        "from transformers4rec.torch.utils.examples_utils import wipe_memory"
      ],
      "metadata": {
        "id": "8ClrrcC3f8pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from merlin_standard_lib import Schema\n",
        "\n",
        "# Define schema object to pass it to the TabularSequenceFeatures class\n",
        "SCHEMA_PATH = '/content/drive/MyDrive/dataset_rees46/processed_nvt/schema.pbtxt'\n",
        "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
        "schema = schema.select_by_name(['product_id-list'])\n",
        "\n"
      ],
      "metadata": {
        "id": "dvUIqRW6gBbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema"
      ],
      "metadata": {
        "id": "RSlLAqlEgGgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09714ce0-7659-48f3-bdcb-3d8103884f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'product_id-list', 'value_count': {'min': '2', 'max': '20'}, 'type': 'INT', 'int_domain': {'name': 'product_id', 'max': '166795', 'is_categorical': True}, 'annotation': {'tag': ['item', 'id', 'list', 'item_id', 'categorical'], 'comment': ['{\"freq_threshold\": 0.0, \"start_index\": 1.0, \"is_list\": true, \"embedding_sizes\": {\"dimension\": 512.0, \"cardinality\": 166796.0}, \"cat_path\": \".//categories/unique.product_id.parquet\", \"max_size\": 0.0, \"is_ragged\": true, \"num_buckets\": null, \"dtype_item_size\": 64.0}']}}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -50 $SCHEMA_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMJfBODDb7qL",
        "outputId": "977108f8-8adc-44f1-c140-3de5c204e727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature {\n",
            "  name: \"product_id-count\"\n",
            "  type: INT\n",
            "  int_domain {\n",
            "    name: \"product_id\"\n",
            "    max: 166795\n",
            "    is_categorical: true\n",
            "  }\n",
            "  annotation {\n",
            "    tag: \"categorical\"\n",
            "    extra_metadata {\n",
            "      type_url: \"type.googleapis.com/google.protobuf.Struct\"\n",
            "      value: \"\\n\\034\\n\\017dtype_item_size\\022\\t\\021\\000\\000\\000\\000\\000\\000@@\\nG\\n\\017embedding_sizes\\0224*2\\n\\026\\n\\tdimension\\022\\t\\021\\000\\000\\000\\000\\000\\000\\200@\\n\\030\\n\\013cardinality\\022\\t\\021\\000\\000\\000\\000`\\\\\\004A\\n\\033\\n\\016freq_threshold\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n\\017\\n\\tis_ragged\\022\\002 \\000\\n\\r\\n\\007is_list\\022\\002 \\000\\n\\021\\n\\013num_buckets\\022\\002\\010\\000\\n\\025\\n\\010max_size\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n5\\n\\010cat_path\\022)\\032\\'.//categories/unique.product_id.parquet\\n\\030\\n\\013start_index\\022\\t\\021\\000\\000\\000\\000\\000\\000\\360?\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "feature {\n",
            "  name: \"user_session\"\n",
            "  type: INT\n",
            "  int_domain {\n",
            "    name: \"user_session\"\n",
            "    max: 9244422\n",
            "    is_categorical: true\n",
            "  }\n",
            "  annotation {\n",
            "    tag: \"categorical\"\n",
            "    extra_metadata {\n",
            "      type_url: \"type.googleapis.com/google.protobuf.Struct\"\n",
            "      value: \"\\n7\\n\\010cat_path\\022+\\032).//categories/unique.user_session.parquet\\n\\034\\n\\017dtype_item_size\\022\\t\\021\\000\\000\\000\\000\\000\\000P@\\n\\021\\n\\013num_buckets\\022\\002\\010\\000\\n\\033\\n\\016freq_threshold\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n\\030\\n\\013start_index\\022\\t\\021\\000\\000\\000\\000\\000\\000\\360?\\n\\025\\n\\010max_size\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n\\r\\n\\007is_list\\022\\002 \\000\\nG\\n\\017embedding_sizes\\0224*2\\n\\030\\n\\013cardinality\\022\\t\\021\\000\\000\\000\\340\\340\\241aA\\n\\026\\n\\tdimension\\022\\t\\021\\000\\000\\000\\000\\000\\000\\200@\\n\\017\\n\\tis_ragged\\022\\002 \\000\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "feature {\n",
            "  name: \"product_id-list\"\n",
            "  value_count {\n",
            "    min: 2\n",
            "    max: 20\n",
            "  }\n",
            "  type: INT\n",
            "  int_domain {\n",
            "    name: \"product_id\"\n",
            "    max: 166795\n",
            "    is_categorical: true\n",
            "  }\n",
            "  annotation {\n",
            "    tag: \"item\"\n",
            "    tag: \"id\"\n",
            "    tag: \"list\"\n",
            "    tag: \"item_id\"\n",
            "    tag: \"categorical\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Input \n",
        "sequence_length, d_model = 20, 320\n",
        "\n",
        "# Define input module to process tabular input-features and to prepare masked inputs\n",
        "inputs= tr.TabularSequenceFeatures.from_schema(\n",
        "    schema,\n",
        "    max_sequence_length=sequence_length,\n",
        "    d_output=d_model,\n",
        "    masking=\"mlm\",\n",
        ")"
      ],
      "metadata": {
        "id": "ynXFo18KgHFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "id": "LBGwGL2VhSVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd904d7-32a6-4dd5-c6b6-de8206cafc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularSequenceFeatures(\n",
              "  (to_merge): ModuleDict(\n",
              "    (categorical_module): SequenceEmbeddingFeatures(\n",
              "      (filter_features): FilterFeatures()\n",
              "      (embedding_tables): ModuleDict(\n",
              "        (product_id-list): Embedding(166796, 64, padding_idx=0)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (_aggregation): ConcatFeatures()\n",
              "  (projection_module): SequentialBlock(\n",
              "    (0): DenseBlock(\n",
              "      (0): Linear(in_features=64, out_features=320, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (_masking): MaskedLanguageModeling()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La tecnica di tying embedding è spesso usata in NLP e \"collega\" i pesi dell'input embedding con la matrice dell'output projection layer. \n",
        "Questo viene fatto perchè l'input e l'output dei modelli sono nello stesso spazio, cioè sono delle parole (in NLP) e dovrebbero ricadere nello stesso spazio vettoriale. \n",
        "I modelli di rec sys in modo analogo hanno gli item id come input e come output. \n",
        "\n",
        "si ridurrebbero i parametri del modello, poichè il numero di embeddings delle features categoriche ad alta cardinalità sono molto maggiori rispetto a NLP. \n",
        "Un altro beneficio è che si ha una regolarizzazione del modello, adattando la sua complessità ai dati.\n",
        "\n",
        "I modelli rec sys di deep learing sono generalmente limitati dallo spazio di memoria disponibile durante il training e l'evaluation (sono memory-bound) e molti parametri sono concentrati in grandi tabelle di embedding. Qui subentra la tecnica di tying embedding che riduce i requisiti di memoria utilizzando soltanto una matrice di proiezione sia per gli item sia per le rappresentazioni dell'output. \n",
        "Questa riduzione dei parametri non è il solo motivo per cui si utilizza la tecnica di tying embedding. \n",
        "Questa tecnica introduce inoltre una operazione di fattorizzazione della matrice tra gli item embeddings e la rappresentazione finale della sessione. \n",
        "\n"
      ],
      "metadata": {
        "id": "xy3GnShAkwmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import transformers4rec.config.transformer as hf\n",
        "\n",
        "transformer_config = tr.AlbertConfig.build(\n",
        "    d_model=d_model, \n",
        "    item_embedding_dim = 320,\n",
        "    n_head=8, \n",
        "    n_layer=2, \n",
        "    total_seq_length=sequence_length, \n",
        "    stochastic_shared_embeddings_replacement_prob = 0.06, #regularization\n",
        "    input_dropout = 0.1,\n",
        "    dropout = 0.0, #regularization\n",
        "    label_smoothing = 0.2, #regularization (proved to be useful in train/val accuracy)\n",
        "    weight_decay = 9.565968888623912e-05, #regularization,\n",
        "    item_id_embeddings_init_std = 0.11,\n",
        "    mlm_probability = 0.6,\n",
        "    eval_on_last_item_seq_only = True,\n",
        "    mf_constrained_embeddings = True,\n",
        "    layer_norm_featurewise = True,\n",
        "    num_hidden_groups = 1,\n",
        "    inner_group_num = 1\n",
        ")\n",
        "\n",
        "# Define the model block including: inputs, masking, projection and transformer block.\n",
        "body = tr.SequentialBlock(\n",
        "    inputs,\n",
        "    tr.MLPBlock([d_model]),\n",
        "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
        ")\n",
        "\n",
        "# Define the head for to next item prediction task \n",
        "head = tr.Head(\n",
        "    body,\n",
        "    tr.NextItemPredictionTask(weight_tying=True,\n",
        "                              metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  \n",
        "                                       RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",
        ")\n",
        "\n",
        "# Get the end-to-end Model class \n",
        "model = tr.Model(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM_kaI5aoUnl",
        "outputId": "6f27f331-d8a2-41f8-94f7-9f7a150473a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers4rec:Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '320' to be equal to the item-id embedding dimension '64'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
        "from transformers4rec.torch import Trainer\n",
        "from transformers4rec.torch.utils.data_utils import MerlinDataLoader\n",
        "\n",
        "#Set arguments for training \n",
        "training_args = T4RecTrainingArguments(\n",
        "            output_dir=\"/content/drive/MyDrive/dataset_rees46/bert\",\n",
        "            max_sequence_length=20,\n",
        "            data_loader_engine='merlin',\n",
        "            num_train_epochs=10, \n",
        "            dataloader_drop_last=True,\n",
        "            compute_metrics_each_n_steps = 1,\n",
        "            per_device_train_batch_size = 192,\n",
        "            per_device_eval_batch_size = 512,\n",
        "            gradient_accumulation_steps = 1,\n",
        "            learning_rate=0.0004904752786458524,\n",
        "            report_to = [],\n",
        "            logging_steps=200,\n",
        "        )"
      ],
      "metadata": {
        "id": "WRi3Y222lFGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    schema=schema,\n",
        "    compute_metrics=True,\n",
        ")"
      ],
      "metadata": {
        "id": "XjB5EyEuli7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/content/drive/MyDrive/dataset_rees46/sessions_by_day\")"
      ],
      "metadata": {
        "id": "kM7aqsDJltlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time_window_index = 1\n",
        "final_time_window_index = 31\n",
        "for time_index in range(start_time_window_index, final_time_window_index):\n",
        "    # Set data \n",
        "    time_index_train = time_index\n",
        "    time_index_eval = time_index + 1\n",
        "    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n",
        "    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/test.parquet\"))\n",
        "    # Train on day related to time_index \n",
        "    print('*'*20)\n",
        "    print(\"Launch training for day %s are:\" %time_index)\n",
        "    print('*'*20 + '\\n')\n",
        "    trainer.train_dataset_or_path = train_paths\n",
        "    trainer.reset_lr_scheduler()\n",
        "    trainer.train()\n",
        "    trainer.state.global_step +=1\n",
        "    # Evaluate on the following day\n",
        "    trainer.eval_dataset_or_path = eval_paths\n",
        "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
        "    print('*'*20)\n",
        "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
        "    print('\\n' + '*'*20 + '\\n')\n",
        "    for key in sorted(train_metrics.keys()):\n",
        "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
        "    wipe_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P19RlRFilwg_",
        "outputId": "df65550e-f112-4611-fe6f-7210de581afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 1 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 111936\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5830\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5830' max='5830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5830/5830 02:28, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>10.444900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>9.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>8.929000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>8.661400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>8.598300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>8.467800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>8.353100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>8.291800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>8.197000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>8.093600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>8.035400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>8.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>7.877500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>7.798800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>7.705900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>7.613500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>7.587400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>7.500700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>7.450300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>7.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>7.324700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>7.259900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>7.290300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>7.207900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>7.205300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>7.178500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>7.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>7.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>7.110800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='827' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 1:14:37]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 2 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 8.172948837280273\n",
            " eval_/next-item/ndcg_at_10 = 0.0967572033405304\n",
            " eval_/next-item/ndcg_at_20 = 0.11630704253911972\n",
            " eval_/next-item/recall_at_10 = 0.18117186427116394\n",
            " eval_/next-item/recall_at_20 = 0.25898435711860657\n",
            " eval_runtime = 0.7703\n",
            " eval_samples_per_second = 16617.182\n",
            " eval_steps_per_second = 32.455\n",
            "********************\n",
            "Launch training for day 2 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 105984\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5520\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5520' max='5520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5520/5520 02:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.814700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>7.751100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>7.625900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>7.473700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>7.420600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>7.294500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>7.194800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>7.197200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>7.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.997600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.863400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.818700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.767500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.711400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.691000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.617200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.589700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.579900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.500600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.486700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.503700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.448700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.424200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.427000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>6.377800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>6.400600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 3 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.575089931488037\n",
            " eval_/next-item/ndcg_at_10 = 0.1283506155014038\n",
            " eval_/next-item/ndcg_at_20 = 0.15097562968730927\n",
            " eval_/next-item/recall_at_10 = 0.23802649974822998\n",
            " eval_/next-item/recall_at_20 = 0.32753056287765503\n",
            " eval_runtime = 0.708\n",
            " eval_samples_per_second = 16632.994\n",
            " eval_steps_per_second = 32.486\n",
            "********************\n",
            "Launch training for day 3 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 97728\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5090\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5090' max='5090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5090/5090 02:06, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.231500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>7.212100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>7.118300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.960900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.974300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.819800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.826700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.745300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.708600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.681700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.555700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.556000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.473100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.500200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.418100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.379400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.394000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.342200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.304400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.295700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.276400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.275000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.246000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.273100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 4 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.2072367668151855\n",
            " eval_/next-item/ndcg_at_10 = 0.14284388720989227\n",
            " eval_/next-item/ndcg_at_20 = 0.16713716089725494\n",
            " eval_/next-item/recall_at_10 = 0.2571614682674408\n",
            " eval_/next-item/recall_at_20 = 0.3532552123069763\n",
            " eval_runtime = 0.9195\n",
            " eval_samples_per_second = 16704.711\n",
            " eval_steps_per_second = 32.626\n",
            "********************\n",
            "Launch training for day 4 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 124416\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6480\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6480' max='6480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6480/6480 02:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.897200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.862600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.828900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.723700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.644400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.653500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.590900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.529000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.503600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.424700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.387000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.411400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.348900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.316300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.299500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.259500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.180500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.215500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.197700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.180400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.128800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.111300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.109400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.062800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.079900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>6.085000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>6.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>6.026300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>6.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>6.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.978200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.979900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 5 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.051671981811523\n",
            " eval_/next-item/ndcg_at_10 = 0.15136845409870148\n",
            " eval_/next-item/ndcg_at_20 = 0.17786242067813873\n",
            " eval_/next-item/recall_at_10 = 0.27531829476356506\n",
            " eval_/next-item/recall_at_20 = 0.38035300374031067\n",
            " eval_runtime = 0.835\n",
            " eval_samples_per_second = 16555.863\n",
            " eval_steps_per_second = 32.336\n",
            "********************\n",
            "Launch training for day 5 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 114432\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5960\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5960' max='5960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5960/5960 02:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.708900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.654200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.652500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.525500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.497700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.431300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.374100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.401900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.274200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.314100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.265700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.214600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.223400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.186700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.156800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.065600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.096800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.047000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.997300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.994600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.965900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.965000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.940200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.935200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 6 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.763752460479736\n",
            " eval_/next-item/ndcg_at_10 = 0.17027194797992706\n",
            " eval_/next-item/ndcg_at_20 = 0.19678239524364471\n",
            " eval_/next-item/recall_at_10 = 0.30743634700775146\n",
            " eval_/next-item/recall_at_20 = 0.41218170523643494\n",
            " eval_runtime = 0.8305\n",
            " eval_samples_per_second = 16644.78\n",
            " eval_steps_per_second = 32.509\n",
            "********************\n",
            "Launch training for day 6 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 112704\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5870\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5870' max='5870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5870/5870 02:24, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.561600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.509300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.441100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.388700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.358400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.256500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.271300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.226700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.194900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.190100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.139500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.109100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.093200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.057900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.027800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.949100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.943400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.940600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.919100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.900200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.853900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.922800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.842700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.851400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.807300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 7 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.939610481262207\n",
            " eval_/next-item/ndcg_at_10 = 0.1629038006067276\n",
            " eval_/next-item/ndcg_at_20 = 0.1900152713060379\n",
            " eval_/next-item/recall_at_10 = 0.29499998688697815\n",
            " eval_/next-item/recall_at_20 = 0.4020312428474426\n",
            " eval_runtime = 0.7982\n",
            " eval_samples_per_second = 16035.94\n",
            " eval_steps_per_second = 31.32\n",
            "********************\n",
            "Launch training for day 7 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 105600\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5500' max='5500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5500/5500 02:15, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.618700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.584600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.530500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.433400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.456300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.346800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.347800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.345700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.249400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.246800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.272300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.183300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.171500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.107500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.091700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.056800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.026700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.973400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.956500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.952900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.963500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.959500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.914500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 8 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.901777744293213\n",
            " eval_/next-item/ndcg_at_10 = 0.16624481976032257\n",
            " eval_/next-item/ndcg_at_20 = 0.19264362752437592\n",
            " eval_/next-item/recall_at_10 = 0.3043619990348816\n",
            " eval_/next-item/recall_at_20 = 0.4089193046092987\n",
            " eval_runtime = 0.9413\n",
            " eval_samples_per_second = 16317.851\n",
            " eval_steps_per_second = 31.871\n",
            "********************\n",
            "Launch training for day 8 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 124992\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6510' max='6510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6510/6510 02:40, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.694000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.612900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.611300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.571800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.482600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.431100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.397000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.372500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.387800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.335400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.262700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.307500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.268300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.181600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.194300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.197500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.146000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.081800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.025400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>6.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.951400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.976300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.988500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>6.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.927900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 9 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.901921272277832\n",
            " eval_/next-item/ndcg_at_10 = 0.17226850986480713\n",
            " eval_/next-item/ndcg_at_20 = 0.19845454394817352\n",
            " eval_/next-item/recall_at_10 = 0.31088361144065857\n",
            " eval_/next-item/recall_at_20 = 0.4143318831920624\n",
            " eval_runtime = 0.9113\n",
            " eval_samples_per_second = 16292.646\n",
            " eval_steps_per_second = 31.822\n",
            "********************\n",
            "Launch training for day 9 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 120768\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6290\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6290' max='6290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6290/6290 02:34, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.593700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.477100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.476300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.446500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.418400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.362000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.333700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.277100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.263000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.314400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.268000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.181300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.201900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.156400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.139200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.067500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.026900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.022100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.995600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.987900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.988400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.931600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.954700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.962400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 10 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.931536674499512\n",
            " eval_/next-item/ndcg_at_10 = 0.17533372342586517\n",
            " eval_/next-item/ndcg_at_20 = 0.20105977356433868\n",
            " eval_/next-item/recall_at_10 = 0.31850406527519226\n",
            " eval_/next-item/recall_at_20 = 0.42042824625968933\n",
            " eval_runtime = 0.8419\n",
            " eval_samples_per_second = 16419.596\n",
            " eval_steps_per_second = 32.07\n",
            "********************\n",
            "Launch training for day 10 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 112320\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5850\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5850' max='5850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5850/5850 02:23, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.585800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.514500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.468800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.439000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.441100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.345600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.338000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.333800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.258100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.256600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.253200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.187600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.185100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.210500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.131700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.114800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.089800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.050200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.101400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.993800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.987900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>6.009800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.968100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.989900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.984800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 11 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.8886542320251465\n",
            " eval_/next-item/ndcg_at_10 = 0.1705126166343689\n",
            " eval_/next-item/ndcg_at_20 = 0.19679485261440277\n",
            " eval_/next-item/recall_at_10 = 0.31158447265625\n",
            " eval_/next-item/recall_at_20 = 0.41552734375\n",
            " eval_runtime = 1.0035\n",
            " eval_samples_per_second = 16326.135\n",
            " eval_steps_per_second = 31.887\n",
            "********************\n",
            "Launch training for day 11 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 132480\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6900\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6900' max='6900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6900/6900 02:49, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.599400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.620100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.592000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.501500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.457500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.488300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.434100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.377800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.374400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.377800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.280200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.228200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.208100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.223600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.213500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.194000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.148400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.125500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.084400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>6.111700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.066600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>6.033400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>6.078400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>6.062300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>6.031600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>6.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>6.016300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.967700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>6.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>5.988700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 12 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.781890869140625\n",
            " eval_/next-item/ndcg_at_10 = 0.1765429973602295\n",
            " eval_/next-item/ndcg_at_20 = 0.20335368812084198\n",
            " eval_/next-item/recall_at_10 = 0.3169102668762207\n",
            " eval_/next-item/recall_at_20 = 0.42300906777381897\n",
            " eval_runtime = 0.9587\n",
            " eval_samples_per_second = 16555.297\n",
            " eval_steps_per_second = 32.335\n",
            "********************\n",
            "Launch training for day 12 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 128640\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6700\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6700' max='6700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6700/6700 02:45, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.482400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.487600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.491500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.408900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.353400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.330300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.287200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.282200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.244800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.263300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.210400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.165500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.147900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.146000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.149500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.125200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.065500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.084600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.026700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>6.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>6.022400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.931600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.964700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.987000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.966400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.946100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.927800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.923400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.871400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.879100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>5.914600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 13 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.719053745269775\n",
            " eval_/next-item/ndcg_at_10 = 0.1803516000509262\n",
            " eval_/next-item/ndcg_at_20 = 0.20826466381549835\n",
            " eval_/next-item/recall_at_10 = 0.3229549527168274\n",
            " eval_/next-item/recall_at_20 = 0.43342140316963196\n",
            " eval_runtime = 1.0762\n",
            " eval_samples_per_second = 16175.719\n",
            " eval_steps_per_second = 31.593\n",
            "********************\n",
            "Launch training for day 13 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 141312\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7360\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7360' max='7360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7360/7360 03:02, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.427900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.369400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.377800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.323400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.299000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.276100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.193200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.208800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.194200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.211800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.091800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.038600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.014300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.964900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.006200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.972100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.944300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.968600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.921000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.885200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.900500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.900800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.893000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.899500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.821400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.905400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>5.851700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>5.844900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>5.820300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>5.855600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-7000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 14 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.743072032928467\n",
            " eval_/next-item/ndcg_at_10 = 0.1836458444595337\n",
            " eval_/next-item/ndcg_at_20 = 0.21032269299030304\n",
            " eval_/next-item/recall_at_10 = 0.3291666805744171\n",
            " eval_/next-item/recall_at_20 = 0.4345052242279053\n",
            " eval_runtime = 0.9397\n",
            " eval_samples_per_second = 16345.856\n",
            " eval_steps_per_second = 31.925\n",
            "********************\n",
            "Launch training for day 14 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 127296\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6630\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6630' max='6630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6630/6630 02:43, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.421200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.424800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.318300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.236100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.271700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.237100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.191800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.148200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.170500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.119400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.086500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.063100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.987800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.958200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.938200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.919000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.912100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.897500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.889500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.845900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.866100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.884000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.834700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.799900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>5.843800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 15 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.749814510345459\n",
            " eval_/next-item/ndcg_at_10 = 0.1830327808856964\n",
            " eval_/next-item/ndcg_at_20 = 0.21049407124519348\n",
            " eval_/next-item/recall_at_10 = 0.32891845703125\n",
            " eval_/next-item/recall_at_20 = 0.437744140625\n",
            " eval_runtime = 0.9939\n",
            " eval_samples_per_second = 16484.302\n",
            " eval_steps_per_second = 32.196\n",
            "********************\n",
            "Launch training for day 15 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 136320\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7100' max='7100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7100/7100 02:54, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.440100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.431000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.408400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.374500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.331500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.305300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.214400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.229300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.187000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.174300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.171400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.127000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.094000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.060100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.047100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.007600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.991100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.923500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.950700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.956600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.927100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.894100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.886000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.930900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.889900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.868900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.849000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.877200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>5.852900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>5.838500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>5.820900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-7000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 16 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.754256248474121\n",
            " eval_/next-item/ndcg_at_10 = 0.18291352689266205\n",
            " eval_/next-item/ndcg_at_20 = 0.20987385511398315\n",
            " eval_/next-item/recall_at_10 = 0.3280029296875\n",
            " eval_/next-item/recall_at_20 = 0.43487548828125\n",
            " eval_runtime = 0.9861\n",
            " eval_samples_per_second = 16614.687\n",
            " eval_steps_per_second = 32.451\n",
            "********************\n",
            "Launch training for day 16 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 133632\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6960\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6960' max='6960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6960/6960 02:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.438500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.384300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.397300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.290300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.303200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.257900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.276100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.214800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.187600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.177400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.131400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.112600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.108400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.093500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.059700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.998000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.033300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.014400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.951900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.966500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.944400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.961000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.924200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.946000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.882000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.880800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.885300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.886800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.856900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>5.861600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>5.862300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 17 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.7532243728637695\n",
            " eval_/next-item/ndcg_at_10 = 0.18470366299152374\n",
            " eval_/next-item/ndcg_at_20 = 0.21100293099880219\n",
            " eval_/next-item/recall_at_10 = 0.3298087418079376\n",
            " eval_/next-item/recall_at_20 = 0.4336611032485962\n",
            " eval_runtime = 0.9088\n",
            " eval_samples_per_second = 16338.18\n",
            " eval_steps_per_second = 31.911\n",
            "********************\n",
            "Launch training for day 17 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 122304\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6370\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6370' max='6370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6370/6370 02:36, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.441000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.429200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.422900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.330700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.302400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.226700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.191100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.207800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.170600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.154600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.053400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.069200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.023900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.996500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.934000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.949400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.932400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.914300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.903600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.917300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.922600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.883800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.872500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.892700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.868900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.827500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 18 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.943165302276611\n",
            " eval_/next-item/ndcg_at_10 = 0.17806600034236908\n",
            " eval_/next-item/ndcg_at_20 = 0.2048434466123581\n",
            " eval_/next-item/recall_at_10 = 0.31766632199287415\n",
            " eval_/next-item/recall_at_20 = 0.4233240783214569\n",
            " eval_runtime = 0.979\n",
            " eval_samples_per_second = 16212.851\n",
            " eval_steps_per_second = 31.666\n",
            "********************\n",
            "Launch training for day 18 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 129216\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6730\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6730' max='6730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6730/6730 02:45, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.556200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.534800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.463100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.418200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.374000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.342900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.316200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.229800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.279700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.227600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.170500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.157800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.130800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>6.133700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.085600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>6.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>6.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>6.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.040500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.979400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.953800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.930300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.990500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.911700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.922100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.910900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.869800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.891200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.913700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.859600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.819700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>5.875200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 19 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.6992106437683105\n",
            " eval_/next-item/ndcg_at_10 = 0.1832534521818161\n",
            " eval_/next-item/ndcg_at_20 = 0.21079809963703156\n",
            " eval_/next-item/recall_at_10 = 0.32974138855934143\n",
            " eval_/next-item/recall_at_20 = 0.4386449456214905\n",
            " eval_runtime = 0.8889\n",
            " eval_samples_per_second = 16703.902\n",
            " eval_steps_per_second = 32.625\n",
            "********************\n",
            "Launch training for day 19 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 122304\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6370\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6370' max='6370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6370/6370 02:36, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.355900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.357800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.321400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.238900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.214900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.200100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.168300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.107400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.052200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.961100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>6.006100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.916200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.927400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.905600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.878700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.909500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.865300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.870800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.874000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.822400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.817600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.813400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.822600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.782300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.799700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.794100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 20 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.460631847381592\n",
            " eval_/next-item/ndcg_at_10 = 0.1958910971879959\n",
            " eval_/next-item/ndcg_at_20 = 0.2234266698360443\n",
            " eval_/next-item/recall_at_10 = 0.3473958373069763\n",
            " eval_/next-item/recall_at_20 = 0.45631512999534607\n",
            " eval_runtime = 0.9378\n",
            " eval_samples_per_second = 16379.63\n",
            " eval_steps_per_second = 31.991\n",
            "********************\n",
            "Launch training for day 20 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 126528\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6590\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6590' max='6590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6590/6590 02:44, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.225400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.220400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.175900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.165100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.124400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.042700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.021700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.946700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.924000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.944900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.900500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.873800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.860900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.894900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.816600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.842500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.810500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.771200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.756700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.814600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.775900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.732900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.734100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.693300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.710400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.720800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.694900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.707100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.687300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 21 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.49577522277832\n",
            " eval_/next-item/ndcg_at_10 = 0.19414766132831573\n",
            " eval_/next-item/ndcg_at_20 = 0.22212117910385132\n",
            " eval_/next-item/recall_at_10 = 0.34334591031074524\n",
            " eval_/next-item/recall_at_20 = 0.45373114943504333\n",
            " eval_runtime = 0.8908\n",
            " eval_samples_per_second = 16667.383\n",
            " eval_steps_per_second = 32.553\n",
            "********************\n",
            "Launch training for day 21 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 120960\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6300\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6300' max='6300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6300/6300 02:35, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.231900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.172700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.161300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.099200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.084500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.062300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.966400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.992200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.960700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.909000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.891800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.877400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.810900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.836000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.830900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.796800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.783800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.780400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.743200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.744300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.770200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.701900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.710300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.697700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.673900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.682000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.661700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.677800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.658800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.630100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 22 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.5262908935546875\n",
            " eval_/next-item/ndcg_at_10 = 0.19691981375217438\n",
            " eval_/next-item/ndcg_at_20 = 0.22496281564235687\n",
            " eval_/next-item/recall_at_10 = 0.3478583097457886\n",
            " eval_/next-item/recall_at_20 = 0.45858028531074524\n",
            " eval_runtime = 0.9089\n",
            " eval_samples_per_second = 16335.489\n",
            " eval_steps_per_second = 31.905\n",
            "********************\n",
            "Launch training for day 22 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 122496\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6380\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6380' max='6380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6380/6380 02:37, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.225400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.161200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.171400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.038600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.103200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.991100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.957100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.992700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.934800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.903300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.917300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.860900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.814200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.852500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.763500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.825100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.747900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.719100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.709800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.725900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.705100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.665900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.650300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.680600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.650400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.666900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.622000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 23 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.540719509124756\n",
            " eval_/next-item/ndcg_at_10 = 0.1977466642856598\n",
            " eval_/next-item/ndcg_at_20 = 0.2259296476840973\n",
            " eval_/next-item/recall_at_10 = 0.3477236032485962\n",
            " eval_/next-item/recall_at_20 = 0.45932111144065857\n",
            " eval_runtime = 0.9183\n",
            " eval_samples_per_second = 16169.782\n",
            " eval_steps_per_second = 31.582\n",
            "********************\n",
            "Launch training for day 23 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 120384\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6270\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6270' max='6270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6270/6270 02:35, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.195500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.178100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.043800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.047800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.963300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.947900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.968600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.887400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.869400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.900200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.844400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.793400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.857700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.799800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.764200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.774600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.780600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.733700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.738100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.705000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.701900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.659200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.669300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.647100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.624500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.657300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 24 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.449972152709961\n",
            " eval_/next-item/ndcg_at_10 = 0.20032663643360138\n",
            " eval_/next-item/ndcg_at_20 = 0.22844848036766052\n",
            " eval_/next-item/recall_at_10 = 0.35380497574806213\n",
            " eval_/next-item/recall_at_20 = 0.46498844027519226\n",
            " eval_runtime = 0.8374\n",
            " eval_samples_per_second = 16507.756\n",
            " eval_steps_per_second = 32.242\n",
            "********************\n",
            "Launch training for day 24 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 113280\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5900\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5900' max='5900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5900/5900 02:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.148500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.096100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.044700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.044000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.929200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.939700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.934400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.845500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.873700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.792000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.827200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.760200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.770600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.732900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.735200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.718300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.709100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.652000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.666300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.665800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.653200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.642700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.637600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.594500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.613300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 25 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.529910087585449\n",
            " eval_/next-item/ndcg_at_10 = 0.19284354150295258\n",
            " eval_/next-item/ndcg_at_20 = 0.22051723301410675\n",
            " eval_/next-item/recall_at_10 = 0.3443359434604645\n",
            " eval_/next-item/recall_at_20 = 0.45423179864883423\n",
            " eval_runtime = 0.9525\n",
            " eval_samples_per_second = 16126.051\n",
            " eval_steps_per_second = 31.496\n",
            "********************\n",
            "Launch training for day 25 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 125376\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6530\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6530' max='6530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6530/6530 02:40, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.165500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.165200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.054900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.973100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.934100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.945800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.887000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.852700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.854400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.842300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.800700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.812800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.779900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.742600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.723500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.743400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.714800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.674000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.715300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.685000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.648400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.638200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.686200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.602800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.612200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.583800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>5.586900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>5.600800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 26 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.394448280334473\n",
            " eval_/next-item/ndcg_at_10 = 0.20124149322509766\n",
            " eval_/next-item/ndcg_at_20 = 0.22814559936523438\n",
            " eval_/next-item/recall_at_10 = 0.35293692350387573\n",
            " eval_/next-item/recall_at_20 = 0.45912906527519226\n",
            " eval_runtime = 0.8568\n",
            " eval_samples_per_second = 16134.56\n",
            " eval_steps_per_second = 31.513\n",
            "********************\n",
            "Launch training for day 26 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 114432\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5960\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5960' max='5960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5960/5960 02:26, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.053000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.033300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>5.961000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.915900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.921200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.841400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.867700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.821600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.798400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.748400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.782000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.698400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.705200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.710800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.635400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.667100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.666700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.613400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.570700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.604600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.539300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.539400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.546800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.560900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.551400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 27 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.301319599151611\n",
            " eval_/next-item/ndcg_at_10 = 0.20679794251918793\n",
            " eval_/next-item/ndcg_at_20 = 0.2346506118774414\n",
            " eval_/next-item/recall_at_10 = 0.36342594027519226\n",
            " eval_/next-item/recall_at_20 = 0.47345197200775146\n",
            " eval_runtime = 0.8364\n",
            " eval_samples_per_second = 16527.925\n",
            " eval_steps_per_second = 32.281\n",
            "********************\n",
            "Launch training for day 27 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 115776\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6030\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6030' max='6030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6030/6030 02:28, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.010900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>5.881800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.916300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.893700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.804800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.797500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.819200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.737300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.736400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.743800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.677000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.678100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.714000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.632300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.635100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.582100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.596900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.608200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.509400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.574600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.541900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.533300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.525400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.495200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>5.499300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.513400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-6000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 28 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.402892589569092\n",
            " eval_/next-item/ndcg_at_10 = 0.20498305559158325\n",
            " eval_/next-item/ndcg_at_20 = 0.23336003720760345\n",
            " eval_/next-item/recall_at_10 = 0.36215445399284363\n",
            " eval_/next-item/recall_at_20 = 0.47430890798568726\n",
            " eval_runtime = 0.8024\n",
            " eval_samples_per_second = 16590.321\n",
            " eval_steps_per_second = 32.403\n",
            "********************\n",
            "Launch training for day 28 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 110016\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5730\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5730' max='5730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5730/5730 02:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.031600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>5.944600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.926600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.893200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.846500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.856100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.821700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.765500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.782700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.728900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.717100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.698100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.666300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.630300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.640500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.604600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.591900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.603400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.563300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.583600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.570200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.552700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.552600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.537900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>5.520300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 29 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.384833812713623\n",
            " eval_/next-item/ndcg_at_10 = 0.20521201193332672\n",
            " eval_/next-item/ndcg_at_20 = 0.23246820271015167\n",
            " eval_/next-item/recall_at_10 = 0.3602343797683716\n",
            " eval_/next-item/recall_at_20 = 0.4678124785423279\n",
            " eval_runtime = 0.7791\n",
            " eval_samples_per_second = 16428.666\n",
            " eval_steps_per_second = 32.087\n",
            "********************\n",
            "Launch training for day 29 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 107328\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 192\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 192\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5590\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5590' max='5590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5590/5590 02:17, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.094200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.039500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>5.981500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.899000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.867100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.819700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.795600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.723700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.751000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.707700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.664100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.600800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.649300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.630800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>5.623400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>5.590400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>5.544300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>5.587700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.543000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>5.550700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>5.519400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-3500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-4500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to /content/drive/MyDrive/dataset_rees46/bert/checkpoint-5500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 30 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.447874546051025\n",
            " eval_/next-item/ndcg_at_10 = 0.20332306623458862\n",
            " eval_/next-item/ndcg_at_20 = 0.23116347193717957\n",
            " eval_/next-item/recall_at_10 = 0.35789060592651367\n",
            " eval_/next-item/recall_at_20 = 0.4682031273841858\n",
            " eval_runtime = 0.7713\n",
            " eval_samples_per_second = 16595.475\n",
            " eval_steps_per_second = 32.413\n",
            "CPU times: user 2h 34min 7s, sys: 1min 43s, total: 2h 35min 50s\n",
            "Wall time: 1h 17min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BERT results:\")\n",
        "for key, value in  model.compute_metrics().items(): \n",
        "  print('%s: %s' % (key, value.item()))"
      ],
      "metadata": {
        "id": "6Eo_ETB9l2Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bb8987-9dcf-4d75-b27f-94036da4ec85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT results:\n",
            "next-item/ndcg_at_10: 0.20332306623458862\n",
            "next-item/ndcg_at_20: 0.23116347193717957\n",
            "next-item/recall_at_10: 0.35789060592651367\n",
            "next-item/recall_at_20: 0.4682031273841858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/dataset_rees46/results.txt\", 'w') as f:\n",
        "    f.write('\\n')\n",
        "    f.write('Albert - MLM:')\n",
        "    f.write('\\n')\n",
        "    for key, value in  model.compute_metrics().items(): \n",
        "        f.write('%s %s\\n' % (key, value.item()))"
      ],
      "metadata": {
        "id": "q9SHIOGR9KJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9Cx4gsXQGV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}