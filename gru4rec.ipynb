{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GRU4REC "
      ],
      "metadata": {
        "id": "fnR08FR8m-Vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "htNj0z5YkKgh",
        "outputId": "9ae992c9-d26b-4866-90a6-6256a44b3de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers4rec[nvtabular,pytorch]\n",
            "  Downloading transformers4rec-0.1.16.tar.gz (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (1.22.4)\n",
            "Collecting betterproto<2.0.0\n",
            "  Downloading betterproto-1.2.5.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (4.64.1)\n",
            "Collecting transformers<4.19\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=1.0 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (9.0.0)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.8/dist-packages (from transformers4rec[nvtabular,pytorch]) (1.13.1+cu116)\n",
            "Collecting torchmetrics>=0.10.0\n",
            "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 KB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvtabular\n",
            "  Downloading nvtabular-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stringcase\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting grpclib\n",
            "  Downloading grpclib-0.4.3.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0->transformers4rec[nvtabular,pytorch]) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics>=0.10.0->transformers4rec[nvtabular,pytorch]) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers<4.19->transformers4rec[nvtabular,pytorch]) (6.0)\n",
            "Collecting merlin-core>=0.2.0\n",
            "  Downloading merlin-core-0.10.0.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting merlin-dataloader>=0.0.2\n",
            "  Downloading merlin-dataloader-0.0.4.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nvtabular->transformers4rec[nvtabular,pytorch]) (1.10.1)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->transformers4rec[nvtabular,pytorch]) (1.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->transformers4rec[nvtabular,pytorch]) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->transformers4rec[nvtabular,pytorch]) (1.58.0)\n",
            "Collecting distributed>=2022.3.0\n",
            "  Downloading distributed-2023.3.0-py3-none-any.whl (945 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m945.4/945.4 KB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (0.56.4)\n",
            "Collecting dask>=2022.3.0\n",
            "  Downloading dask-2023.3.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.3.5)\n",
            "Collecting fsspec==2022.5.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->transformers4rec[nvtabular,pytorch]) (6.0.4)\n",
            "Collecting h2<5,>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers<4.19->transformers4rec[nvtabular,pytorch]) (1.26.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<4.19->transformers4rec[nvtabular,pytorch]) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<4.19->transformers4rec[nvtabular,pytorch]) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<4.19->transformers4rec[nvtabular,pytorch]) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.3.0)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.0.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.4.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (3.1.2)\n",
            "Collecting psutil>=5.7.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zict>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.2.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.7.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.0.4)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (6.2)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2022.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.10.3->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (2.1.2)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=2.1.0->distributed>=2022.3.0->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.54->merlin-core>=0.2.0->nvtabular->transformers4rec[nvtabular,pytorch]) (3.15.0)\n",
            "Building wheels for collected packages: betterproto, transformers4rec, merlin-core, merlin-dataloader, grpclib, sacremoses, stringcase\n",
            "  Building wheel for betterproto (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for betterproto: filename=betterproto-1.2.5-py3-none-any.whl size=22012 sha256=bff5a98d21aa4f9fc960a2b1823f1f34de0712138aef96181a93fe1878978745\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/d8/2c/88deaa4bcf85c355055d31aebbc3b8e554ab38fd0823aa6f08\n",
            "  Building wheel for transformers4rec (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers4rec: filename=transformers4rec-0.1.16-py3-none-any.whl size=481577 sha256=9849d36f9a106b0df772793716774316ae9c54d2d9126e6aca30757f5bed1ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/c0/d7/3d7d885412e6a92068a3f4149f6e84d0e5c49fd558118ae1bc\n",
            "  Building wheel for merlin-core (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for merlin-core: filename=merlin_core-0.10.0-py3-none-any.whl size=118957 sha256=a6605cece085777e3a96efbe4a218d6dd21a8cb0d8b3159a231ebe5c5621d18e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/61/f5/248b8e08a868d53576e56cab6d8dcad527c28a69499cf8486a\n",
            "  Building wheel for merlin-dataloader (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for merlin-dataloader: filename=merlin_dataloader-0.0.4-py3-none-any.whl size=40636 sha256=b74df564f62031cb9b988222256f5cc2095b13c76641195bd30ac10a78cdff0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/e2/06/e3d8eefc51ce919c86894c57ed23356ff99c8194635fe60f56\n",
            "  Building wheel for grpclib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.3-py3-none-any.whl size=77081 sha256=1fc90c467124323b353a6c5d2fcf74c5e8efebc5425cd0a59d8aaa4b36ce630d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/bf/37/810d98c051f7709adc84c97077afaef55a58725f879fc7f780\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=041b5dc7e99193b1812dff6d8f54eb6b5120580dee4aed7a523990b134aac33b\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3587 sha256=8c90bee9671c6fa606822fc324482f9d53c73787c6e7fd83ed6d4dd30cb4b8a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/0e/31/bf265c64f2a4d24516e9923f1f6293c3bcbcde75e0d80ab47a\n",
            "Successfully built betterproto transformers4rec merlin-core merlin-dataloader grpclib sacremoses stringcase\n",
            "Installing collected packages: tokenizers, stringcase, sacremoses, psutil, hyperframe, hpack, fsspec, torchmetrics, huggingface-hub, h2, dask, transformers, grpclib, distributed, betterproto, transformers4rec, merlin-core, merlin-dataloader, nvtabular\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.1.0\n",
            "    Uninstalling fsspec-2023.1.0:\n",
            "      Successfully uninstalled fsspec-2023.1.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.2.1\n",
            "    Uninstalling dask-2022.2.1:\n",
            "      Successfully uninstalled dask-2022.2.1\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.2.1\n",
            "    Uninstalling distributed-2022.2.1:\n",
            "      Successfully uninstalled distributed-2022.2.1\n",
            "Successfully installed betterproto-1.2.5 dask-2023.3.0 distributed-2023.3.0 fsspec-2022.5.0 grpclib-0.4.3 h2-4.1.0 hpack-4.0.0 huggingface-hub-0.12.1 hyperframe-6.0.1 merlin-core-0.10.0 merlin-dataloader-0.0.4 nvtabular-1.8.1 psutil-5.9.4 sacremoses-0.0.53 stringcase-1.2.0 tokenizers-0.12.1 torchmetrics-0.11.3 transformers-4.18.0 transformers4rec-0.1.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers4rec[pytorch,nvtabular]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIR3-VRKnDmq",
        "outputId": "8e90a7c1-badb-4718-c0c0-a53cbbaf5085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import torch \n",
        "import transformers4rec.torch as tr\n",
        "\n",
        "from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt\n",
        "from transformers4rec.torch.utils.examples_utils import wipe_memory"
      ],
      "metadata": {
        "id": "LhbxqV26nEeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from merlin_standard_lib import Schema\n",
        "\n",
        "# Define schema object to pass it to the TabularSequenceFeatures class\n",
        "SCHEMA_PATH = '/content/drive/MyDrive/dataset_rees46/processed_nvt/schema.pbtxt'\n",
        "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
        "\n",
        "# Create a sub-schema only with the selected features\n",
        "schema = schema.select_by_name(['product_id-list_seq'])"
      ],
      "metadata": {
        "id": "CSRdjqj9nIIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsoGtltLnQv5",
        "outputId": "ca2364f2-c5ea-4ed6-ed18-f46c6d14cacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'product_id-list_seq', 'value_count': {'min': '2', 'max': '20'}, 'type': 'INT', 'int_domain': {'name': 'product_id', 'max': '166795', 'is_categorical': True}, 'annotation': {'tag': ['list', 'item_id', 'id', 'categorical', 'item'], 'comment': ['{\"is_ragged\": true, \"embedding_sizes\": {\"dimension\": 512.0, \"cardinality\": 166796.0}, \"is_list\": true, \"freq_threshold\": 0.0, \"dtype_item_size\": 64.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.product_id.parquet\", \"max_size\": 0.0, \"num_buckets\": null}']}}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 20\n",
        "inputs = tr.TabularSequenceFeatures.from_schema(\n",
        "        schema,\n",
        "        max_sequence_length= sequence_length,\n",
        "        masking = 'causal',\n",
        "    )"
      ],
      "metadata": {
        "id": "9ptVw71OrCyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 128\n",
        "body = tr.SequentialBlock(\n",
        "        inputs, \n",
        "        tr.MLPBlock([d_model]), #projection MLP layer\n",
        "        tr.Block(torch.nn.GRU(input_size=d_model, \n",
        "                              hidden_size=d_model, \n",
        "                              num_layers=1, \n",
        "                              dropout=0.0, #regularization\n",
        "                              ), \\\n",
        "                 [None, 20, d_model]) #GRU model\n",
        ")"
      ],
      "metadata": {
        "id": "qv7nXoBgrM5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head = tr.Head(\n",
        "    body,\n",
        "    tr.NextItemPredictionTask(weight_tying=True, \n",
        "                              metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  \n",
        "                                       RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",
        ")\n",
        "\n",
        "model = tr.Model(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KInB2DOZrfnj",
        "outputId": "0d19c207-a0a5-4da1-8553-5ffbb234f92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers4rec:Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '128' to be equal to the item-id embedding dimension '64'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import NVTabular dependencies\n",
        "from transformers4rec.torch.utils.data_utils import MerlinDataLoader\n",
        "\n",
        "x_cat_names, x_cont_names = ['product_id-list_seq'], [] #categorical and continuous features\n",
        "\n",
        "# dictionary representing max sequence length for each column - needed in the dataloader function\n",
        "# [column_name: integer] as [key: value]\n",
        "sparse_features_max = {\n",
        "    fname: sequence_length for fname in x_cat_names + x_cont_names\n",
        "}\n",
        "\n",
        "# Define a `get_dataloader` function to call in the training loop\n",
        "def get_dataloader(path, batch_size=32):\n",
        "\n",
        "    return MerlinDataLoader.from_schema(\n",
        "        schema, \n",
        "        path, \n",
        "        batch_size, #number of samples to yield at each iteration\n",
        "        max_sequence_length=sequence_length, \n",
        "        sparse_names=x_cat_names + x_cont_names, #list with column names of columns that should be represented as sparse tensors\n",
        "        sparse_max=sparse_features_max, #dictionary of [column_name: integer] as [key: value], representing max sequence lenght for each column\n",
        ")\n",
        "    "
      ],
      "metadata": {
        "id": "u95hmSTZrlMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
        "from transformers4rec.torch import Trainer\n",
        "\n",
        "#Set arguments for training \n",
        "train_args = T4RecTrainingArguments(local_rank = -1, \n",
        "                                    dataloader_drop_last = False,\n",
        "                                    report_to = [],   #set empty list to avoid logging metrics to Weights&Biases\n",
        "                                    gradient_accumulation_steps = 1,\n",
        "                                    per_device_train_batch_size = 448, \n",
        "                                    per_device_eval_batch_size = 512,\n",
        "                                    output_dir = \"./gru\", \n",
        "                                    max_sequence_length=sequence_length,\n",
        "                                    learning_rate=0.0007107976722774954,\n",
        "                                    num_train_epochs=10,\n",
        "                                    logging_steps=200,\n",
        "                                    weight_decay=4.0070030423993165e-06,         \n",
        "                                   )"
      ],
      "metadata": {
        "id": "6yfxLD3Mrt2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    schema=schema,\n",
        "    compute_metrics=True,\n",
        ")"
      ],
      "metadata": {
        "id": "dIt56Wm0sAFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/content/drive/MyDrive/dataset_rees46/sessions_by_day\")"
      ],
      "metadata": {
        "id": "gAb7mrt7taV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time_window_index = 1\n",
        "final_time_window_index = 30\n",
        "for time_index in range(start_time_window_index, final_time_window_index):\n",
        "    # Set data \n",
        "    time_index_train = time_index\n",
        "    time_index_eval = time_index + 1\n",
        "    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n",
        "    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/test.parquet\"))\n",
        "    \n",
        "    # Initialize dataloaders\n",
        "    trainer.train_dataloader = get_dataloader(train_paths, train_args.per_device_train_batch_size)\n",
        "    trainer.eval_dataloader = get_dataloader(eval_paths, train_args.per_device_eval_batch_size)\n",
        "    \n",
        "    # Train on day related to time_index \n",
        "    print('*'*20)\n",
        "    print(\"Launch training for day %s are:\" %time_index)\n",
        "    print('*'*20 + '\\n')\n",
        "    trainer.reset_lr_scheduler()\n",
        "    trainer.train()\n",
        "    trainer.state.global_step +=1\n",
        "    \n",
        "    # Evaluate on the following day\n",
        "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
        "    print('*'*20)\n",
        "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
        "    print('\\n' + '*'*20 + '\\n')\n",
        "    for key in sorted(train_metrics.keys()):\n",
        "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
        "    wipe_memory()\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NmrDZ2qItdri",
        "outputId": "4ef91f1e-41b2-4652-9ae0-6a0da91f4d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 112448\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 1 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2510' max='2510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2510/2510 05:46, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>10.030400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>9.033600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>8.833500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>8.672500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>8.512100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>8.359900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>8.242200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>8.164000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>8.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>8.029400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>7.966000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>7.940600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='856' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 3:01:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 2 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 8.556951522827148\n",
            " eval_/next-item/ndcg_at_10 = 0.06896374374628067\n",
            " eval_/next-item/ndcg_at_20 = 0.08415067195892334\n",
            " eval_/next-item/recall_at_10 = 0.12966495752334595\n",
            " eval_/next-item/recall_at_20 = 0.1898038536310196\n",
            " eval_runtime = 2.2688\n",
            " eval_samples_per_second = 5867.406\n",
            " eval_steps_per_second = 11.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 106176\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 2 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2370/2370 05:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>8.526900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>8.197500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>8.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>7.824400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>7.665000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>7.545600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>7.422100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>7.313700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>7.250100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>7.201500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>7.137100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 3 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 8.200451850891113\n",
            " eval_/next-item/ndcg_at_10 = 0.10441578179597855\n",
            " eval_/next-item/ndcg_at_20 = 0.12525855004787445\n",
            " eval_/next-item/recall_at_10 = 0.19518917798995972\n",
            " eval_/next-item/recall_at_20 = 0.2776246666908264\n",
            " eval_runtime = 2.0975\n",
            " eval_samples_per_second = 5858.312\n",
            " eval_steps_per_second = 11.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 98112\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 3 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2190' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2190/2190 05:04, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.899400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>7.550100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>7.324100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>7.136900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>7.022300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.891100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.817600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.731000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.676900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.616400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 4 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.667614936828613\n",
            " eval_/next-item/ndcg_at_10 = 0.13246335089206696\n",
            " eval_/next-item/ndcg_at_20 = 0.1555863469839096\n",
            " eval_/next-item/recall_at_10 = 0.23896509408950806\n",
            " eval_/next-item/recall_at_20 = 0.3308197259902954\n",
            " eval_runtime = 2.5084\n",
            " eval_samples_per_second = 6327.482\n",
            " eval_steps_per_second = 12.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 124544\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 4 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2780/2780 06:16, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.409000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>7.105900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.963800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.837800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.704800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.617400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.556900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.468400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.364200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.338900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.281000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.264700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 5 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.268002033233643\n",
            " eval_/next-item/ndcg_at_10 = 0.14750072360038757\n",
            " eval_/next-item/ndcg_at_20 = 0.1712849885225296\n",
            " eval_/next-item/recall_at_10 = 0.269091933965683\n",
            " eval_/next-item/recall_at_20 = 0.36343690752983093\n",
            " eval_runtime = 2.2245\n",
            " eval_samples_per_second = 6444.576\n",
            " eval_steps_per_second = 12.587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 114688\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 5 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2560' max='2560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2560/2560 05:57, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.111800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.853300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.679500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.569400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.473400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.378000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.312600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.264600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.158600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.116200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.109200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 6 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.962644577026367\n",
            " eval_/next-item/ndcg_at_10 = 0.16212917864322662\n",
            " eval_/next-item/ndcg_at_20 = 0.18853668868541718\n",
            " eval_/next-item/recall_at_10 = 0.2926005721092224\n",
            " eval_/next-item/recall_at_20 = 0.39683908224105835\n",
            " eval_runtime = 2.1952\n",
            " eval_samples_per_second = 6530.634\n",
            " eval_steps_per_second = 12.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 112896\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 6 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2520' max='2520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2520/2520 05:56, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.863700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.635700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.498900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.393500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.321600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.226400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.174100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.107000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.086000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.041300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.998100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.970500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 7 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.230011940002441\n",
            " eval_/next-item/ndcg_at_10 = 0.1603071689605713\n",
            " eval_/next-item/ndcg_at_20 = 0.18604101240634918\n",
            " eval_/next-item/recall_at_10 = 0.2810012102127075\n",
            " eval_/next-item/recall_at_20 = 0.3828077018260956\n",
            " eval_runtime = 2.1082\n",
            " eval_samples_per_second = 6314.475\n",
            " eval_steps_per_second = 12.333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 106176\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 7 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2370' max='2370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2370/2370 05:25, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.922100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.640400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.478600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.387000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.306400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.230400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.167800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.095400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.034600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.994900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 8 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.191165924072266\n",
            " eval_/next-item/ndcg_at_10 = 0.16094809770584106\n",
            " eval_/next-item/ndcg_at_20 = 0.18656374514102936\n",
            " eval_/next-item/recall_at_10 = 0.2880041301250458\n",
            " eval_/next-item/recall_at_20 = 0.3891545832157135\n",
            " eval_runtime = 2.7165\n",
            " eval_samples_per_second = 5842.721\n",
            " eval_steps_per_second = 11.412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 125440\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 8 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 06:16, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.930700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.666200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.397100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.291300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.226200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.969200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.926700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.919800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.888800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 9 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.055368900299072\n",
            " eval_/next-item/ndcg_at_10 = 0.16505153477191925\n",
            " eval_/next-item/ndcg_at_20 = 0.19078698754310608\n",
            " eval_/next-item/recall_at_10 = 0.2921694815158844\n",
            " eval_/next-item/recall_at_20 = 0.3941405117511749\n",
            " eval_runtime = 2.352\n",
            " eval_samples_per_second = 6530.719\n",
            " eval_steps_per_second = 12.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 120960\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 9 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2700/2700 06:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.833800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.609100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.365200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.241800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.179200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.145100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.077100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.950700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.924700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.904100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 10 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.052510738372803\n",
            " eval_/next-item/ndcg_at_10 = 0.16450147330760956\n",
            " eval_/next-item/ndcg_at_20 = 0.1904015839099884\n",
            " eval_/next-item/recall_at_10 = 0.29021787643432617\n",
            " eval_/next-item/recall_at_20 = 0.3928004801273346\n",
            " eval_runtime = 2.2077\n",
            " eval_samples_per_second = 6493.743\n",
            " eval_steps_per_second = 12.683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 112448\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 10 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2510' max='2510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2510/2510 05:43, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.814800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.564200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.416900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.315500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.247100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.155900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.979700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.934900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.937200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 11 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 7.06924295425415\n",
            " eval_/next-item/ndcg_at_10 = 0.16303104162216187\n",
            " eval_/next-item/ndcg_at_20 = 0.18931087851524353\n",
            " eval_/next-item/recall_at_10 = 0.286636620759964\n",
            " eval_/next-item/recall_at_20 = 0.3904251456260681\n",
            " eval_runtime = 2.6776\n",
            " eval_samples_per_second = 6310.149\n",
            " eval_steps_per_second = 12.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 133056\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 11 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2970' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2970/2970 06:46, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.841700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.516200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.380600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.336400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.286600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.197400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.156800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.139100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.063000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>6.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>6.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.986000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 12 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.8026628494262695\n",
            " eval_/next-item/ndcg_at_10 = 0.17655861377716064\n",
            " eval_/next-item/ndcg_at_20 = 0.2028297632932663\n",
            " eval_/next-item/recall_at_10 = 0.308700829744339\n",
            " eval_/next-item/recall_at_20 = 0.4125211536884308\n",
            " eval_runtime = 2.5368\n",
            " eval_samples_per_second = 6458.644\n",
            " eval_steps_per_second = 12.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 129024\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 12 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2880/2880 06:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.701900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.505600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.403000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.271800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.196900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.165700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.103800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.045200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.936500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.938800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.895400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.889700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 13 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.782118797302246\n",
            " eval_/next-item/ndcg_at_10 = 0.17487448453903198\n",
            " eval_/next-item/ndcg_at_20 = 0.20216841995716095\n",
            " eval_/next-item/recall_at_10 = 0.3064239025115967\n",
            " eval_/next-item/recall_at_20 = 0.41469138860702515\n",
            " eval_runtime = 2.7744\n",
            " eval_samples_per_second = 6459.141\n",
            " eval_steps_per_second = 12.616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 141568\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 13 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3160' max='3160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3160/3160 07:40, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.627000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.485100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.358600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.243700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.216500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.138900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.058400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.988300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.911500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.887300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.855900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 14 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.873451232910156\n",
            " eval_/next-item/ndcg_at_10 = 0.17688722908496857\n",
            " eval_/next-item/ndcg_at_20 = 0.20279911160469055\n",
            " eval_/next-item/recall_at_10 = 0.3109941780567169\n",
            " eval_/next-item/recall_at_20 = 0.4137078523635864\n",
            " eval_runtime = 2.519\n",
            " eval_samples_per_second = 6300.862\n",
            " eval_steps_per_second = 12.306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 127680\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 14 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2850' max='2850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2850/2850 06:28, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.687100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.482700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.257400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.168100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.156100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.989500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.981300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.919200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.917600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.892000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.869200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 15 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.913034915924072\n",
            " eval_/next-item/ndcg_at_10 = 0.17673413455486298\n",
            " eval_/next-item/ndcg_at_20 = 0.20286160707473755\n",
            " eval_/next-item/recall_at_10 = 0.3078886568546295\n",
            " eval_/next-item/recall_at_20 = 0.41146790981292725\n",
            " eval_runtime = 2.7392\n",
            " eval_samples_per_second = 6168.323\n",
            " eval_steps_per_second = 12.048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 136640\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 15 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3050' max='3050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3050/3050 06:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.712700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.520700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.274000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.184700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.082300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.034700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.973100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.985300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.934500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.901300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.901900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.887000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-3000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 16 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.816497802734375\n",
            " eval_/next-item/ndcg_at_10 = 0.17237703502178192\n",
            " eval_/next-item/ndcg_at_20 = 0.20014719665050507\n",
            " eval_/next-item/recall_at_10 = 0.3005322217941284\n",
            " eval_/next-item/recall_at_20 = 0.41066890954971313\n",
            " eval_runtime = 2.629\n",
            " eval_samples_per_second = 6426.799\n",
            " eval_steps_per_second = 12.552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 133952\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 16 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2990' max='2990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2990/2990 06:46, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.698600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.549800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.418700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.213100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.117800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.098400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.061100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.981000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.971500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.921700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.942200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 17 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.8630051612854\n",
            " eval_/next-item/ndcg_at_10 = 0.17371462285518646\n",
            " eval_/next-item/ndcg_at_20 = 0.2008541077375412\n",
            " eval_/next-item/recall_at_10 = 0.3070470988750458\n",
            " eval_/next-item/recall_at_20 = 0.4142394959926605\n",
            " eval_runtime = 2.4097\n",
            " eval_samples_per_second = 6374.352\n",
            " eval_steps_per_second = 12.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 122752\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 17 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2740' max='2740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2740/2740 06:16, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.726100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.505600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.403200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.277000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.187900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.137500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.100900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.042400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.978400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.984400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.944900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.911300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.897000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 18 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.938830375671387\n",
            " eval_/next-item/ndcg_at_10 = 0.17115545272827148\n",
            " eval_/next-item/ndcg_at_20 = 0.19789279997348785\n",
            " eval_/next-item/recall_at_10 = 0.29710325598716736\n",
            " eval_/next-item/recall_at_20 = 0.40292173624038696\n",
            " eval_runtime = 2.7856\n",
            " eval_samples_per_second = 5881.63\n",
            " eval_steps_per_second = 11.488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 129472\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 18 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2890' max='2890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2890/2890 06:38, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.577000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.449900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.347600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.255700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.218000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.168300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.094800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.046000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>6.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.982900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.985900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.944500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 19 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.758204460144043\n",
            " eval_/next-item/ndcg_at_10 = 0.1762077808380127\n",
            " eval_/next-item/ndcg_at_20 = 0.2018938809633255\n",
            " eval_/next-item/recall_at_10 = 0.30744338035583496\n",
            " eval_/next-item/recall_at_20 = 0.40922001004219055\n",
            " eval_runtime = 2.6961\n",
            " eval_samples_per_second = 5697.12\n",
            " eval_steps_per_second = 11.127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 122752\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 19 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2740' max='2740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2740/2740 06:24, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.496100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.372000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.268600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.189300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.133300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.112900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>6.038300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>6.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.973700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.951800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.929000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.898400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 20 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.657688617706299\n",
            " eval_/next-item/ndcg_at_10 = 0.1762889325618744\n",
            " eval_/next-item/ndcg_at_20 = 0.20377801358699799\n",
            " eval_/next-item/recall_at_10 = 0.3105581998825073\n",
            " eval_/next-item/recall_at_20 = 0.4195215106010437\n",
            " eval_runtime = 2.491\n",
            " eval_samples_per_second = 6371.642\n",
            " eval_steps_per_second = 12.445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 126784\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 20 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2830' max='2830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2830/2830 06:39, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.385300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.256500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.166400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.096600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.042200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.939300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.913300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.904300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.839800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.828600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.816900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 21 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.585776329040527\n",
            " eval_/next-item/ndcg_at_10 = 0.17935973405838013\n",
            " eval_/next-item/ndcg_at_20 = 0.20785623788833618\n",
            " eval_/next-item/recall_at_10 = 0.31589511036872864\n",
            " eval_/next-item/recall_at_20 = 0.42841851711273193\n",
            " eval_runtime = 2.3874\n",
            " eval_samples_per_second = 6433.678\n",
            " eval_steps_per_second = 12.566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 121408\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 21 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2710/2710 06:07, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.534400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.340700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.222200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.139500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.046100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.010100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.949900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.909500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.867400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.850700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.818900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.793600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.785600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 22 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.713311195373535\n",
            " eval_/next-item/ndcg_at_10 = 0.17409691214561462\n",
            " eval_/next-item/ndcg_at_20 = 0.20020562410354614\n",
            " eval_/next-item/recall_at_10 = 0.3065548837184906\n",
            " eval_/next-item/recall_at_20 = 0.4099280536174774\n",
            " eval_runtime = 2.4406\n",
            " eval_samples_per_second = 6293.439\n",
            " eval_steps_per_second = 12.292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 122752\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 22 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2740' max='2740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2740/2740 06:14, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.546000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.352100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.248300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.155200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.051400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.030700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.971500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.934200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.886100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.860500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.850200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.801600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.808200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 23 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.694944381713867\n",
            " eval_/next-item/ndcg_at_10 = 0.17823679745197296\n",
            " eval_/next-item/ndcg_at_20 = 0.20460617542266846\n",
            " eval_/next-item/recall_at_10 = 0.31222692131996155\n",
            " eval_/next-item/recall_at_20 = 0.41668346524238586\n",
            " eval_runtime = 2.3627\n",
            " eval_samples_per_second = 6501.133\n",
            " eval_steps_per_second = 12.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 120512\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 23 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2690' max='2690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2690/2690 06:09, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.565400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.362100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.244800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.170900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.030300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.977700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.940600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.891700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.880500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.829300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.812200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 24 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.676004409790039\n",
            " eval_/next-item/ndcg_at_10 = 0.1763627827167511\n",
            " eval_/next-item/ndcg_at_20 = 0.20387418568134308\n",
            " eval_/next-item/recall_at_10 = 0.30993273854255676\n",
            " eval_/next-item/recall_at_20 = 0.41899242997169495\n",
            " eval_runtime = 2.249\n",
            " eval_samples_per_second = 6374.472\n",
            " eval_steps_per_second = 12.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 113792\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 24 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2540' max='2540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2540/2540 05:48, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.559000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.335300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.219600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.134500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.060800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.995200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.932600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.895100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.874700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.846700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.804600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.795000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 25 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.707900524139404\n",
            " eval_/next-item/ndcg_at_10 = 0.17580153048038483\n",
            " eval_/next-item/ndcg_at_20 = 0.20262713730335236\n",
            " eval_/next-item/recall_at_10 = 0.3115493953227997\n",
            " eval_/next-item/recall_at_20 = 0.41763341426849365\n",
            " eval_runtime = 2.5244\n",
            " eval_samples_per_second = 6287.344\n",
            " eval_steps_per_second = 12.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 125440\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 25 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 06:24, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.531200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.224000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.048100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>6.020700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.910500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.863600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.864200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.826700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.790500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.792500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.776600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 26 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.588900089263916\n",
            " eval_/next-item/ndcg_at_10 = 0.18622387945652008\n",
            " eval_/next-item/ndcg_at_20 = 0.2137880176305771\n",
            " eval_/next-item/recall_at_10 = 0.32405832409858704\n",
            " eval_/next-item/recall_at_20 = 0.4331634044647217\n",
            " eval_runtime = 2.2462\n",
            " eval_samples_per_second = 6382.301\n",
            " eval_steps_per_second = 12.465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 114688\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 26 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2560' max='2560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2560/2560 06:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.477400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.279700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.167200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.092600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.957000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.909200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.878700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.852600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.812700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.794600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.770600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 27 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.601047992706299\n",
            " eval_/next-item/ndcg_at_10 = 0.18162962794303894\n",
            " eval_/next-item/ndcg_at_20 = 0.20858973264694214\n",
            " eval_/next-item/recall_at_10 = 0.318111777305603\n",
            " eval_/next-item/recall_at_20 = 0.42470934987068176\n",
            " eval_runtime = 2.2975\n",
            " eval_samples_per_second = 6239.842\n",
            " eval_steps_per_second = 12.187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 116032\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 27 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 06:13, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.436800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.243000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.142500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.983300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.915900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.857600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.806100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.781000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.749200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.744200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 28 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.605090141296387\n",
            " eval_/next-item/ndcg_at_10 = 0.18436750769615173\n",
            " eval_/next-item/ndcg_at_20 = 0.21161752939224243\n",
            " eval_/next-item/recall_at_10 = 0.32083120942115784\n",
            " eval_/next-item/recall_at_20 = 0.4284135401248932\n",
            " eval_runtime = 2.2324\n",
            " eval_samples_per_second = 6192.535\n",
            " eval_steps_per_second = 12.095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 110208\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 28 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2460' max='2460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2460/2460 05:42, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.467500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.243800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.150600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.033400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.987500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.918500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.863800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.826900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.802600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.774000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.749300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.738400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 29 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.6611480712890625\n",
            " eval_/next-item/ndcg_at_10 = 0.18025419116020203\n",
            " eval_/next-item/ndcg_at_20 = 0.20728495717048645\n",
            " eval_/next-item/recall_at_10 = 0.31490421295166016\n",
            " eval_/next-item/recall_at_20 = 0.42200934886932373\n",
            " eval_runtime = 2.3415\n",
            " eval_samples_per_second = 5685.173\n",
            " eval_steps_per_second = 11.104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 107520\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 448\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 448\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Launch training for day 29 are:\n",
            "********************\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2400' max='2400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2400/2400 05:34, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.527700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.292300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.174300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.953800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.897900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.854200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.828700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.803500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.772800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.762600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./gru/checkpoint-500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-1500\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "Saving model checkpoint to ./gru/checkpoint-2000\n",
            "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********************\n",
            "Eval results for day 30 are:\t\n",
            "\n",
            "********************\n",
            "\n",
            " eval_/loss = 6.6362175941467285\n",
            " eval_/next-item/ndcg_at_10 = 0.1758965700864792\n",
            " eval_/next-item/ndcg_at_20 = 0.20357991755008698\n",
            " eval_/next-item/recall_at_10 = 0.3126915991306305\n",
            " eval_/next-item/recall_at_20 = 0.42205703258514404\n",
            " eval_runtime = 2.0994\n",
            " eval_samples_per_second = 6340.719\n",
            " eval_steps_per_second = 12.384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/dataset_rees46/results.txt\", 'a') as f: \n",
        "    f.write('\\n')\n",
        "    f.write('GRU accuracy results:')\n",
        "    f.write('\\n')\n",
        "    for key, value in  model.compute_metrics().items(): \n",
        "        f.write('%s: %s' % (key, value.item()))"
      ],
      "metadata": {
        "id": "ClKiyqAEtjT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results:\")\n",
        "for key, value in  model.compute_metrics().items(): \n",
        "  print('\\n%s: %s ' % (key, value.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0usKKA6yzqX_",
        "outputId": "679d2cca-e1e9-4284-8a73-705428e0411a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "next-item/ndcg_at_10: 0.1758965700864792 \n",
            "next-item/ndcg_at_20: 0.20357991755008698 \n",
            "next-item/recall_at_10: 0.3126915991306305 \n",
            "next-item/recall_at_20: 0.42205703258514404 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsGpC02Pyy6u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}